{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"VocalTurnTaking_ExampleExperiment.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"N_YQTD_WCcD1"},"source":["# Import packages\n","## this notebook uses some functions that we have not encountered yet\n","* '_sounddevice_' is a package that lets you access your computer's microphone and speaker.\n","    > Unfortunately this only works when python is running locally on your computer. <br>\n","    So we have commented that line of code out (the package does not exist in collaboratory but will be useful when we load python locally on your computer) <br>\n","    Google collaboratory notebooks cannot access your computer's local environment to communicate with your microphone, etc. Instead of using this package to perform the experiment, for now we will look at the results of data that I collected by doing a simple psychophysical experiment on myself.\n","* '_matplotlib.pyplot_' and '_seaborn_' are both packages that contain lots of functions for plotting _arrays_ of numbers (such as a waveform recorded via the microphone)\n","    > https://seaborn.pydata.org/\n","* '_scipy_' is a 'scientific' package that contains functions for processing arrays of numbers (like filtering them or detecting peaks in a signal). Here we will use it to get a _spectrogram_ of our waveform.\n","    > https://en.wikipedia.org/wiki/Spectrogram#:~:text=A%20spectrogram%20is%20a%20visual,sonographs%2C%20voiceprints%2C%20or%20voicegrams.\n","* '_pathlib_' is a package that is used to work with file/directory paths to pass files into and out of functions (such as saving an array to a waveform file on your computer or loading an array from a file)\n","* '_google.colab_' is a package that contains a module (called _drive_) that enables you to interact with the files in your google drive\n","* '_IPython.display_' is a package that contains a module ('Audio') to play arrays in the notebook workspace as audio files out of your microphone\n"]},{"cell_type":"code","metadata":{"id":"ChJwPr0KCcD2"},"source":["import numpy as np\n","# import sounddevice as sd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy import signal\n","from pathlib import Path\n","from google.colab import drive\n","from IPython.display import Audio\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9qqUJEHKCpji"},"source":["# To load the data we will need to connect to your google drive. \n","* Remember to make sure that the data from the experiment is uploaded to your Google drive into a folder named '__data_VocalTurnTaking__'. "]},{"cell_type":"markdown","metadata":{"id":"uDadvPGVEJgf"},"source":["To mount Google Drive, run the below code and go to the link to retireve the authorization code. Paste the authorization code in the box created by running the code and press enter.\n"]},{"cell_type":"code","metadata":{"id":"KdyMn2FfEZjL"},"source":["drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Ai2yu03EjOS"},"source":["\n","\n","Once mounted successfully, your entire Google Drive files should be accessible under /content/gdrive/My\\ Drive/\n","<br>\n","> After mounting Google Drive, you can download datasets into Google Drive to use in the Colab session, or save outputs of the session into your Google Drive.\n","\n","> You can also view the contents of your drive directory by expanding the file folder icon to the left.\n"]},{"cell_type":"code","metadata":{"id":"QiWMVsOVE6m4"},"source":["!ls /content/gdrive/My\\ Drive\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mSRipfqhIkIY"},"source":["Next we will navigate to 'My Drive' using the 'change directory' command (```%cd```)"]},{"cell_type":"code","metadata":{"id":"lOd0uILRIItd"},"source":["%cd gdrive/My\\ Drive"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDh6Z1IOE9bf"},"source":["We will now create a 'pathlib' object that essentially saves the google drive directory as a string that we can pass to 'load' functions."]},{"cell_type":"code","metadata":{"id":"csdI09kWCoLm"},"source":["savepath = Path('data_VocalTurnTaking')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8xAiF00iJyUT"},"source":["# Now that we have access to the data for the experiment, let's explore the experiment and its data."]},{"cell_type":"markdown","metadata":{"id":"2xSDTnV4K9cK"},"source":["## Run the following cell to specify some \"_metadata_\" about the data collected.\n","> https://en.wikipedia.org/wiki/Metadata"]},{"cell_type":"code","metadata":{"id":"zWaRO1whMLnF"},"source":["sampleRate = 20000\n","duration = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3607-JxJ-4m"},"source":["## Experiment Part I) First, a human 'call' was recorded and played to a human test subject.  "]},{"cell_type":"code","metadata":{"id":"iBGbG6NmJBb1"},"source":["# load the call signal/waveform and store it as a local variable named 'call'\n","call = np.load(savepath / 'Hello.npy').flatten()\n","\n","# 'flatten()' changes the shape of the array... \n","# not an important detail for now, but something to keep in mind for future debugging"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TyHaMdZRNI7F"},"source":["We can play the array using the 'Audio' module. When you run the cell below it crates a graphical interface below the code cell with a play button, a volume slider, and the option to download (unecessary since we already have this audio file stored). "]},{"cell_type":"code","metadata":{"id":"oQCiRYRhKg5j"},"source":["# Generate a player for mono sound\n","Audio(call,rate=sampleRate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QogxDYVEOBaX"},"source":["### Waveforms/signals can be visualized in several different ways. Let's examine two ways to visualize the call that you just heard:\n","> (1) as a raw waveform; the units are usually 'Volts.'<br>\n","> (2) as a '_spectrogram_'; the units are frequency ('Hertz').<br>\n","\n","Both of these are plotted as a function of time."]},{"cell_type":"markdown","metadata":{"id":"KjfC70OUPS6K"},"source":["The code below creates a time vector to plot the raw waveform against. It contains the same number of points as the 'call' waveform. It starts at time = 0 seconds and ends at time = 3 seconds. It is convension to name this 'xtime' since it will be plotted on the x-axis."]},{"cell_type":"code","metadata":{"id":"bp-vYPEzMWOC"},"source":["xtime = np.linspace(0, duration, sampleRate * duration) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_QKi7gXPuq9"},"source":["We can now use the matplotlib.pyplot function 'plot' to plot the amplitude of the call signal as a function of time."]},{"cell_type":"code","metadata":{"id":"sHZeOrNAP1ZN"},"source":["# first, make a figure\n","hfig = plt.figure()\n","\n","# The following function takes 'x' and 'y' and plots them:\n","plt.plot(xtime, call) \n","# you can provide other elements to the function\n","# by adding them inside the parentheses (separated by a comma)\n","\n","# BELOW is where you will insert functions to add labels to the plot\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_bOV-VQCQTq2"},"source":["You can change some of the aesthetic features of the plot by passing arguments to the plot() function. \n","> change the color of the line to green by adding ``` color = 'green' ``` to the list of elements passed to the plot function. Try other colors as well. \n","\n","You can also add labels to the plot\n","> Add a line of code to the cell above that uses the ``` plt.xlabel() ``` function to add a label for the x axis describing what is being plotted (time in seconds). <br>\n",">> use the following syntax: ``` plt.xlabel('time, seconds') ``` <br>\n","\n","> Do the same for the y label using ``` plt.ylabel() ``` to specify that the amplitude is in Volts. "]},{"cell_type":"markdown","metadata":{"id":"b7gWemIYSLfa"},"source":["Another helpful way to visualize audio signals is to plot a spectrogram. The '_signal_' module that we imported at the beginning of the notebook has a function for calculating the spectrogram of the signal.\n","> Where specified in the code cell below, add axes labels like you did for the previous plot. (The Y label will be different since this is a plot of frequency against time rather than amplitdue against time)."]},{"cell_type":"code","metadata":{"id":"YdZHQyqsSeYe"},"source":["# First we need to specify parameters to input into the spectrogram function:\n","windur = 0.01 # the duration of each chunk (window) to calculate the power across frequencies\n","winsamp = int(windur*sampleRate) # transforms the window duration into samples\n","\n","# next, we use the spectrogram() function to calculate the spectrogram\n","f, t, Sxx = signal.spectrogram(call,\n","                               fs = sampleRate,\n","                               window = 'hamming',\n","                               nperseg = winsamp,\n","                               noverlap = winsamp/2\n","                              )\n","# f is an array of all the frequency bins analyzed\n","# t is an array of all the time windows analyzed\n","# Sxx is a matrix of the power at a given frequency in a given time window\n","\n","# the 'plt' module has a function that plots this kind of 3-dimensional data\n","plt.pcolormesh(t, f, np.log(Sxx), cmap='plasma') \n","\n","# ADD LABELS FOR THE X AND Y AXES HERE:\n","# remember, a spectrogram is a plot of frequency across time\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Gh5edueUjV1"},"source":["## Experiment Part II) Second, the call was played 20 times (20 trials). On each trial, a human test subject responded to the call with a response. The vocalization of the test subject was recorded on each trial and saved as an array. "]},{"cell_type":"code","metadata":{"id":"rwCdeFFAU7OH"},"source":["# load the matrix of response signals/waveforms and store it as a local variable named 'response_single'\n","ResponseSingle = np.load(savepath / 'ResponseSingle.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IWB6O8CMU3Jb"},"source":["Let's look at the shape of this matrix by using the ``` np.shape() ``` function below."]},{"cell_type":"code","metadata":{"id":"KEcITT0TVMdu"},"source":["np.shape(ResponseSingle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_dLF4GbVYQN"},"source":["This means that the matrix has 20 rows and 60000 columns. Each row is the response on a single trial. Each column is a sample of the amplitude of the signal at each moment in time throughout each trial. \n","> The number of samples is equal to the duration of the recording on each trial (3 seconds) multiplied by the sampling rate (20000 Hertz). This metadata was stored as variables earlier and can be used to calculate the expected number of samples in each row of the matrix:"]},{"cell_type":"code","metadata":{"id":"aoEEkS9NWHkB"},"source":["SamplesPerRow = duration * sampleRate\n","print('Each row should have this many samples: ')\n","print(SamplesPerRow)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CTPr_7yCWsOJ"},"source":["We can look at just one row at a time by assigning a single row to a new variable. <br>\n","The cell below assigns the first row (number '0') to a variable called 'trial0'."]},{"cell_type":"code","metadata":{"id":"_6p3xaGRW50Q"},"source":["trial0 = ResponseSingle[0,:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lk1TGXdeWWsl"},"source":["Using the examples from Part I of the experiment above, create additional code cells below to write code that makes the following plots of the data from the first trial that is saved as the variable '_trial0_':\n","* 1) Plot the amplitude against time\n","* 2) Plot the frequency against time for the spectrogram of the signal.\n","\n","You can even copy and paste most of the code written in Part I into new code cells below and just change the variable for the signal being plotted. The time variable (xtime) that we created before should be the same here."]},{"cell_type":"code","metadata":{"id":"n11pWrAtXh5G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVcLp10nXm4L"},"source":["### Analyzing data from Part II:\n","> What is some of the important information that we want to find out?\n",">> One of the main pieces of information that we want to calculate from the response data is the distribution of repsonse latencies (ie. the time between the start of the call and the start of the response)."]},{"cell_type":"markdown","metadata":{"id":"0X2DnlUNYLUu"},"source":["To calculate this information, we need to first know the onset of the call (in seconds). You can get an approximate estimate of this from looking at the plots you made in Part I.\n","> Look at the plots you made to write an approximate time of call onset in the Markdown cell below:"]},{"cell_type":"markdown","metadata":{"id":"i4-9zicqYrg9"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"nDzZSrKaYwWF"},"source":["To calculate a more exact estimate of the call onset, we will write code that finds when the signal power across frequencies (the absolute magnitude) increases above some threshold value.\n","> To do this, we will use the spectrogram function to get the power at each frequency at each time. Then, for each moment in time, we will use the ``` np.sum() ``` function to add the power across all frequencies. We will call this the __call_envelope__"]},{"cell_type":"code","metadata":{"id":"aKYN5rGwZYBA"},"source":["f, t, Sxx = signal.spectrogram(call,\n","                               fs = sampleRate,\n","                               window = 'hamming',\n","                               nperseg = winsamp,\n","                               noverlap = winsamp/2\n","                              )\n","\n","call_envelope = np.sum(Sxx,0) \n","# the '0' element passed to this function specifies to sum across the first element of the Sxx matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuo0OR1-Zw0e"},"source":["Now we can plot the call_envelope across time to see what it looks like. Remember that '_t_' (one of the outputs of the spectrogram() function) is a vector of the time values for each sample in call_envelope."]},{"cell_type":"code","metadata":{"id":"y5bJ6xrNaCbI"},"source":["# make the figure\n","hfig = plt.figure()\n","\n","# plot the call_envelope against time and color it whatever color you want\n","plt.plot(t, call_envelope, color = 'black')\n","\n","# pick a threshold value and \n","# plot a horizontal line at that value \n","# to see where the call_envelope first goes above that value.\n","threshold = 0.0001\n","plt.hlines(threshold, 0, 3, color = 'red', linestyle = '--')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63eED527avMX"},"source":["We can ask the computer to calculate when the call_envelope rises above the threshold value. We will call this the 'onset' of the call.\n","> To do this we use the '_np.min()_' and '_np.max()_' functions.\n","\n","> We will also need to use a comparison operator ``` > ``` (_greater than_) to find where the call_envelope is greater than the threshold value."]},{"cell_type":"code","metadata":{"id":"vBkVQW0Ja5OH"},"source":["SortingArray = call_envelope > threshold"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2wHf3GSbfDJ"},"source":["Print the _SortingArray_ using the code cell below to see what the information contained in this '_boolean_' array looks like. \n","> a 'boolean' is an array of 'True' and 'False'"]},{"cell_type":"code","metadata":{"id":"gjT6a97Jbu-e"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzU8n0cRbvYc"},"source":["Next, we will filter the time vector '_t_' using this SortingArray and use the np.min() function to find the earliest time at which the call_evelope is above the threshold value."]},{"cell_type":"code","metadata":{"id":"m3dxYqA_cDwL"},"source":["TimesAboveThreshold = t[SortingArray]\n","call_onset = np.min(TimesAboveThreshold)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_6EJQKpcNee"},"source":["print('the call onset is at ')\n","print(call_onset)\n","print('seconds')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZxYSqKGcUQD"},"source":["### Now, that we know the call onset, let's use the same methods to calculate the onset of each response from the test subject\n","> To do this we will use a for loop to perform the calculation on each trial of the response matrix."]},{"cell_type":"code","metadata":{"id":"cmQWGzSDcqao"},"source":["# first, we will create an empty array to put the data \n","# about the envelope of the response on each trial.\n","response_envelope_all = []\n","\n","# next we will loop through the response matrix \n","# and calculate the envelope of the response on each trial\n","# and put that envelope in the matrix using the .append() function.\n","for response in ResponseSingle:\n","    f, t, Sxx = signal.spectrogram(response,\n","                               fs = sampleRate,\n","                               window = 'hamming',\n","                               nperseg = winsamp,\n","                               noverlap = winsamp/2\n","                              )\n","    response_envelope_this_trial = np.sum(Sxx,0)\n","    response_envelope_all.append(response_envelope_this_trial)\n","response_envelope_all = np.asarray(response_envelope_all).T\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xQUKguNdnDN"},"source":["Now we can plot the response_envelope_all matrix against time to visualize the data. Include a line that shows the threhold value. Notice that without any 'color' argument passed to the plot function, each trial (row of the matrix) is automatically plotted in a different color. "]},{"cell_type":"code","metadata":{"id":"k9Tivh6idLBn"},"source":["hfig = plt.figure()\n","plt.plot(t,response_envelope_all);\n","plt.ylabel('power')\n","plt.xlabel('seconds')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsSWWSLddgAh"},"source":["We will now use a for loop to calculate the response onset for each trial using the data in the response_envelope_all matrix that we just created."]},{"cell_type":"code","metadata":{"id":"nSSaaVlMeNpz"},"source":["response_onset = []\n","for response in response_envelope_all.T:\n","  SortingArray = response > threshold\n","  onset = np.min(t[SortingArray])\n","  response_onset.append(onset)\n","response_onset = np.asarray(response_onset).T\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f-i2a94LfEqm"},"source":[" Now we have an array of the response time (in seconds) on each trial, which you can see by printing the array below."]},{"cell_type":"code","metadata":{"id":"ijA-FYNdfCRe"},"source":["print(response_onset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ssKulGgfRlS"},"source":["How would you calculate the response latency on each trial? \n","> First, use the Markdown cell below to write in words the calculation that needs to be done.\n","\n","> Second, use the Code cell below that to write code that performs the calculation and displays the result."]},{"cell_type":"markdown","metadata":{"id":"4JjGAOxlfr-x"},"source":[""]},{"cell_type":"code","metadata":{"id":"0vVL51MCfrQr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKqtjv5Pfypa"},"source":["We can plot the call_envelope and the response_envelope overlaid on the same plot in order to visualize and make an estimate of the approximate response latency to the call that should have been calculated above.\n","* call_envelope is plotted in red and response_envelope_all trials are plotted in black"]},{"cell_type":"code","metadata":{"id":"-GsDD7X7eUB5"},"source":["plt.figure()\n","plt.plot(t,call_envelope,color = 'red')\n","plt.plot(t,response_envelope_all,color = 'black');\n","plt.xlabel('seconds')\n","plt.ylabel('power')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-C9M_-ogbkC"},"source":["# To be continued...."]}]}